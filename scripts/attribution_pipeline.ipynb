{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = \"data/challenge.db\"\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_query = \"\"\"\n",
    "SELECT MIN(event_date) AS start_date, MAX(event_date) AS end_date\n",
    "FROM session_sources\n",
    "\"\"\"\n",
    "start_end_dates = pd.read_sql(start_end_query, conn)\n",
    "print(f\"Data starts from: {start_end_dates['start_date'][0]}\")\n",
    "print(f\"Data ends on: {start_end_dates['end_date'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query, conn)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"PRAGMA table_info(attribution_customer_journey);\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_sources table\n",
    "pd.read_sql_query(\"SELECT * FROM session_sources LIMIT 5;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversions table\n",
    "pd.read_sql_query(\"SELECT * FROM conversions LIMIT 5;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_costs table\n",
    "pd.read_sql_query(\"SELECT * FROM session_costs LIMIT 5;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Range Input\n",
    "####  Allowing to analyze marketing performance for specific time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_table_names(conn):\n",
    "    \"\"\"Fetch all table names in the database for validation.\"\"\"\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    return result['name'].tolist()\n",
    "\n",
    "def get_date_input(prompt):\n",
    "    \"\"\"Function to handle date input validation.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            date_input = input(prompt)\n",
    "            date = pd.to_datetime(date_input, format='%Y-%m-%d')\n",
    "            return date\n",
    "        except ValueError:\n",
    "            print(\"Invalid date format. Please enter the date in 'YYYY-MM-DD' format.\")\n",
    "\n",
    "start_date = get_date_input(\"Enter start date (YYYY-MM-DD): \")\n",
    "end_date = get_date_input(\"Enter end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Converting to string format for SQL query\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Tables to query from\n",
    "valid_tables = get_valid_table_names(conn)\n",
    "print(f\"Available tables: {', '.join(valid_tables)}\")\n",
    "\n",
    "tables_input = input(\"Enter the tables to query from (comma separated): \")\n",
    "tables_to_query = [table.strip() for table in tables_input.split(',')]\n",
    "\n",
    "# Validate table names\n",
    "invalid_tables = [table for table in tables_to_query if table not in valid_tables]\n",
    "if invalid_tables:\n",
    "    print(f\"Invalid table(s): {', '.join(invalid_tables)}. Please select valid table names.\")\n",
    "else:\n",
    "    # Base query \n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM session_sources\n",
    "    \"\"\"\n",
    "\n",
    "    # JOINs if different tables are selected\n",
    "    if 'conversions' in tables_to_query:\n",
    "        query += \" LEFT JOIN conversions ON session_sources.user_id = conversions.user_id\"\n",
    "    if 'session_costs' in tables_to_query:\n",
    "        query += \" LEFT JOIN session_costs ON session_sources.session_id = session_costs.session_id\"\n",
    "\n",
    "    # date filter only for session sources, cost and conversions tables\n",
    "    query += \" WHERE session_sources.event_date BETWEEN ? AND ?\"\n",
    "\n",
    "    # Execute the query with parameters\n",
    "    try:\n",
    "        df = pd.read_sql_query(query, conn, params=(start_date_str, end_date_str))\n",
    "        print(\"Data fetched successfully:\")\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_costs = pd.read_sql_query(\"SELECT * FROM session_costs;\", conn)\n",
    "\n",
    "missing_count = session_costs['cost'].isna().sum()\n",
    "total_count = len(session_costs)\n",
    "\n",
    "print(f\"Missing values in 'cost': {missing_count}\")\n",
    "print(f\"Total rows in 'session_costs': {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_sources = pd.read_sql_query(\"SELECT * FROM session_sources;\", conn)\n",
    "missing_sources = session_sources.isna().sum()\n",
    "\n",
    "conversions = pd.read_sql_query(\"SELECT * FROM conversions;\", conn)\n",
    "missing_conversions = conversions.isna().sum()\n",
    "\n",
    "print(\"Missing values in session_sources:\")\n",
    "print(missing_sources)\n",
    "\n",
    "print(\"\\nMissing values in conversions:\")\n",
    "print(missing_conversions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_sources = session_sources.duplicated().sum()\n",
    "print(f\"Duplicate rows in session_sources: {duplicates_sources}\")\n",
    "\n",
    "duplicates_conversions = conversions.duplicated().sum()\n",
    "print(f\"Duplicate rows in conversions: {duplicates_conversions}\")\n",
    "\n",
    "duplicates_costs = session_costs.duplicated().sum()\n",
    "print(f\"Duplicate rows in session_costs: {duplicates_costs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing NaN with 0.0 ensures that these rows are included in calculations with an appropriate assumption like A user might visit the website through organic search or direct traffic, which typically doesnâ€™t incur a cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_costs['cost'] = session_costs['cost'].fillna(0.0)\n",
    "\n",
    "print(session_costs['cost'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract session_sources\n",
    "session_sources = pd.read_sql_query(\"SELECT * FROM session_sources;\", conn)\n",
    "\n",
    "# Extract conversions\n",
    "conversions = pd.read_sql_query(\"SELECT * FROM conversions;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Session Sources:\")\n",
    "print(session_sources.head())\n",
    "\n",
    "print(\"\\nConversions:\")\n",
    "print(conversions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergeing session sources with conversions on user_id\n",
    "merged = session_sources.merge(conversions, on='user_id', suffixes=('_session', '_conversion'))\n",
    "\n",
    "# Filtering sessions that occurred before conversions using sessions date and time\n",
    "filtered_sessions = merged[\n",
    "    (\n",
    "        (merged['event_date'] < merged['conv_date']) \n",
    "        |  \n",
    "        (\n",
    "            (merged['event_date'] == merged['conv_date']) & \n",
    "            (merged['event_time'] < merged['conv_time'])  \n",
    "        )\n",
    "    )\n",
    "].sort_values(by=['conv_id', 'event_date', 'event_time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping sessions by conv id and convert to dictionary\n",
    "grouped_journeys = filtered_sessions.groupby(\"conv_id\").apply(lambda x: x.to_dict(orient=\"records\")).to_dict()\n",
    "\n",
    "grouped_journeys[list(grouped_journeys.keys())[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped_journeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv_id, sessions in grouped_journeys.items():\n",
    "    for session in sessions:\n",
    "        print(session['channel_name']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform customer journeys Data for API input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_journeys_transformed = {\n",
    "    conv_id: [\n",
    "        {\n",
    "            \"conversion_id\": conv_id, \n",
    "            \"session_id\": session[\"session_id\"],\n",
    "            \"timestamp\": f\"{session['event_date']} {session['event_time']}\",  # Concatenate event date and time for session\n",
    "            \"channel_label\": session[\"channel_name\"],  \n",
    "            \"holder_engagement\": session[\"holder_engagement\"],\n",
    "            \"closer_engagement\": session[\"closer_engagement\"],\n",
    "            \"conversion\": 1 if session[\"conv_id\"] == conv_id else 0,  # Conversion happens if the conv id matches\n",
    "            \"impression_interaction\": session[\"impression_interaction\"],\n",
    "        }\n",
    "        for session in sessions\n",
    "    ]\n",
    "    for conv_id, sessions in grouped_journeys.items()\n",
    "}\n",
    "\n",
    "redistribution_parameter = {\n",
    "    'initializer': {\n",
    "        'direction': 'earlier_sessions_only',\n",
    "        'receive_threshold': 0,\n",
    "        'redistribution_channel_labels': [\n",
    "            'Direct Traffic', \n",
    "            'Newsletter & Email', \n",
    "            'FB & IG Ads', \n",
    "            'TikTok Ads',  \n",
    "            'Paid Search Brand', \n",
    "            'Organic Traffic', \n",
    "            'Referral', \n",
    "            'Affiliate & Partnerships', \n",
    "            'Performance Max', \n",
    "            'Paid Search Non Brand', \n",
    "            'Microsoft Ads', \n",
    "            'Social Organic' \n",
    "        ],\n",
    "    },\n",
    "    'holder': {\n",
    "        'direction': 'any_session',\n",
    "        'receive_threshold': 0,\n",
    "        'redistribution_channel_labels': [\n",
    "            'Direct Traffic', \n",
    "            'Newsletter & Email', \n",
    "            'Organic Traffic', \n",
    "            'FB & IG Ads', \n",
    "            'TikTok Ads', \n",
    "            'Referral', \n",
    "            'Paid Search Non Brand', \n",
    "            'Social Organic', \n",
    "            'Affiliate & Partnerships'\n",
    "        ],\n",
    "    },\n",
    "    'closer': {\n",
    "        'direction': 'later_sessions_only',\n",
    "        'receive_threshold': 0.1,\n",
    "        'redistribution_channel_labels': [\n",
    "            'Paid Search Brand', \n",
    "            'Organic Traffic', \n",
    "            'Referral', \n",
    "            'Performance Max', \n",
    "            'Social Organic'\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "api_data = {\n",
    "    'customer_journeys': grouped_journeys_transformed,\n",
    "    'redistribution_parameter': redistribution_parameter\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('customer_journeys.json', 'w') as f:\n",
    "    json.dump(api_data, f, indent=4)\n",
    "\n",
    "print(\"Data Ready for API:\")\n",
    "print(api_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = '/Users/vee/Desktop/ihc_data_pipeline/customer_journeys.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    api_data = json.load(f)\n",
    "\n",
    "print(api_data.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "json_file_path = 'customer_journeys.json'  \n",
    "csv_file_path = 'customer_journeys.csv'   \n",
    "\n",
    "\n",
    "with open(json_file_path, 'r') as file:\n",
    "    api_data = json.load(file)\n",
    "\n",
    "customer_journeys = api_data['customer_journeys']\n",
    "\n",
    "flattened_data = []\n",
    "for conv_id, sessions in customer_journeys.items():\n",
    "    for session in sessions:\n",
    "        flattened_data.append({\n",
    "            \"conversion_id\": session[\"conversion_id\"],\n",
    "            \"session_id\": session[\"session_id\"],\n",
    "            \"timestamp\": session[\"timestamp\"],\n",
    "            \"channel_label\": session[\"channel_label\"],\n",
    "            \"holder_engagement\": session[\"holder_engagement\"],\n",
    "            \"closer_engagement\": session[\"closer_engagement\"],\n",
    "            \"conversion\": session[\"conversion\"],\n",
    "            \"impression_interaction\": session[\"impression_interaction\"],\n",
    "        })\n",
    "\n",
    "csv_headers = [\n",
    "    \"conversion_id\", \"session_id\", \"timestamp\", \"channel_label\",\n",
    "    \"holder_engagement\", \"closer_engagement\", \"conversion\", \"impression_interaction\"\n",
    "]\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(flattened_data)\n",
    "\n",
    "print(f\"CSV file created at: {csv_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
